{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.0.1.post2\n",
      "Torchvision Version:  0.2.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "trainLabels = pd.read_csv(\"./trainLabels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './train/train_224/*'\n",
    "images_list = glob.glob(train_path)\n",
    "images_list = sorted(images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EyeDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, images_list,labels,transform=None):\n",
    "#         self.X = X\n",
    "#         self.y = y\n",
    "#         self.transform = transforms.Resize(224)\n",
    "        self.images_list = images_list\n",
    "        self.trainLables = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        print(len(self.images_list))\n",
    "        return len(self.images_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "#         print(\"index \",idx)\n",
    "        imgtemp = Image.open(self.images_list[idx])\n",
    "        if self.transform!=None :\n",
    "            imgtemp = self.transform(imgtemp)\n",
    "        img = transforms.ToTensor()(imgtemp)\n",
    "#         fileName = self.images_list[idx].split('/')[-1].split('.')[0]\n",
    "#         imglabel = torch.zeros(5,dtype=torch.long)\n",
    "#         imglabel[self.trainLables.loc[self.trainLables.image==fileName ,'level'].values[0]] = 1\n",
    "        \n",
    "#         xtemp = self.transform(self.X[idx])\n",
    "#         ytemp = self.transform(self.y[idx])\n",
    "        return img ,self.trainLables[idx]\n",
    "\n",
    "class EyeDatasetFromImages(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx],self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_epochs = 1\n",
    "num_classes = 5\n",
    "feature_extract = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input(idx):\n",
    "        imgtemp = Image.open(images_train_list[idx])\n",
    "#         if self.transform!=None :\n",
    "#             imgtemp = self.transform(imgtemp)\n",
    "        img = transforms.ToTensor()(imgtemp)\n",
    "        fileName = images_train_list[idx].split('/')[-1].split('.')[0]\n",
    "        imglabel = torch.zeros(5,dtype=torch.long)\n",
    "        imglabel[trainLabels.loc[trainLabels.image==fileName ,'level'].values[0]] = 1\n",
    "        return img ,imglabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_for_one_image(idx,model):\n",
    "        test , test_label = get_input(idx)\n",
    "        test = test.view(-1,3,224,224)\n",
    "        test_label = test_label.view(-1,5)\n",
    "        test = test.to(device)\n",
    "        test_label = test_label.to(device)\n",
    "        print(\"test_label\",test_label)\n",
    "        pred = model(test)\n",
    "        print(\"pred\",pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(filenames,trainLabels):\n",
    "    labels = []\n",
    "    for file in filenames:\n",
    "        ft = file.split('/')[-1].split('.')[0]\n",
    "        imglabel = torch.zeros(5,dtype=torch.long)\n",
    "        imglabel[trainLabels.loc[trainLabels.image==ft ,'level'].values[0]] = 1\n",
    "        labels.append(imglabel)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"train_balanced_name\",\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_balanced_images = []\n",
    "for line in lines:\n",
    "    temp = line.strip()\n",
    "    temp = './train/train_224/' + temp\n",
    "    total_balanced_images.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train_list , images_test_list = train_test_split(total_balanced_images,test_size=0.1,random_state=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_dict = { 'train' : torch.utils.data.DataLoader(EyeDataset(images_train_list,get_labels(images_train_list,trainLabels)),batch_size=batch_size) }\n",
    "dataloaders_dict['val'] = torch.utils.data.DataLoader(EyeDataset(images_test_list,get_labels(images_test_list,trainLabels)),batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, checkpoint,num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train','val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            num_b = 0\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                num_b += 1\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "#                 print(\"input size \",inputs.size())\n",
    "#                 print(\"label size\",labels.size())\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, torch.max(labels,1)[1])\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == torch.max(labels,1)[1])\n",
    "                \n",
    "                if num_b%35==0 :\n",
    "                    print('loss in {} batch is {:.4f}'.format(num_b,loss))\n",
    "                    torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'loss' : loss,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        }, checkpoint)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet50\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet50(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "    return model_ft , input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model for this run\n",
    "# model_ft, input_size = initialize_model(\"resnet\", num_classes, feature_extract, use_pretrained=True)\n",
    "model_ft = torch.load(\"resnet_balanced7pm\")\n",
    "# model_toy = toy_model()\n",
    "# model_toy.classifier[6] = nn.Linear(4096,num_classes)\n",
    "checkpoint = \"resnet50.checkpoint\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ft = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001  # 0.1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_ft.parameters(), lr=lr, momentum=0.9, nesterov=True, weight_decay=0.0001)\n",
    "is_train = True\n",
    "is_pretrain = True\n",
    "acc_best = 0\n",
    "total_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model = ResidualAttentionModel().cuda()\n",
    "# model = torch.load('residual_an_6pm.model')\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = model.to(device)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/0\n",
      "----------\n",
      "11907\n",
      "loss in 35 batch is 0.1899\n",
      "loss in 70 batch is 0.0726\n",
      "loss in 105 batch is 0.2963\n",
      "loss in 140 batch is 0.1011\n",
      "loss in 175 batch is 0.2417\n",
      "loss in 210 batch is 0.5797\n",
      "loss in 245 batch is 0.0530\n",
      "loss in 280 batch is 0.3242\n",
      "loss in 315 batch is 0.0097\n",
      "loss in 350 batch is 0.7169\n",
      "loss in 385 batch is 0.2243\n",
      "loss in 420 batch is 0.1239\n",
      "loss in 455 batch is 0.1275\n",
      "loss in 490 batch is 0.1163\n",
      "loss in 525 batch is 0.0509\n",
      "loss in 560 batch is 0.0227\n",
      "loss in 595 batch is 0.1120\n",
      "loss in 630 batch is 0.4153\n",
      "loss in 665 batch is 0.2671\n",
      "loss in 700 batch is 0.1432\n",
      "loss in 735 batch is 0.0470\n",
      "loss in 770 batch is 0.2445\n",
      "loss in 805 batch is 0.0478\n",
      "loss in 840 batch is 0.3638\n",
      "loss in 875 batch is 0.0754\n",
      "loss in 910 batch is 0.2449\n",
      "loss in 945 batch is 0.4990\n",
      "loss in 980 batch is 0.0745\n",
      "loss in 1015 batch is 0.1048\n",
      "loss in 1050 batch is 0.0429\n",
      "loss in 1085 batch is 0.1169\n",
      "loss in 1120 batch is 0.0283\n",
      "loss in 1155 batch is 0.2421\n",
      "loss in 1190 batch is 0.0328\n",
      "loss in 1225 batch is 0.0174\n",
      "loss in 1260 batch is 0.0527\n",
      "loss in 1295 batch is 0.2775\n",
      "loss in 1330 batch is 0.0195\n",
      "loss in 1365 batch is 0.3499\n",
      "loss in 1400 batch is 0.1278\n",
      "loss in 1435 batch is 0.2612\n",
      "loss in 1470 batch is 0.0811\n",
      "11907\n",
      "11907\n",
      "train Loss: 0.2135 Acc: 0.9232\n",
      "1323\n",
      "loss in 35 batch is 0.0061\n",
      "loss in 70 batch is 0.0802\n",
      "loss in 105 batch is 0.5259\n",
      "loss in 140 batch is 0.4828\n",
      "1323\n",
      "1323\n",
      "val Loss: 0.1718 Acc: 0.9358\n",
      "\n",
      "Training complete in 6m 51s\n",
      "Best val Acc: 0.935752\n"
     ]
    }
   ],
   "source": [
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer,\n",
    "                             \"balanced_resnet.checkpoint\", num_epochs=num_epochs, is_inception=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft,\"resnet_balanced7pm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft,\"resnet_final12pm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
